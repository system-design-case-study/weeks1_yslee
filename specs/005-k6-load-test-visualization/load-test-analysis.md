# 부하 테스트 분석 보고서

**Branch**: `005-k6-load-test-visualization`
**Date**: 2026-02-09
**Reference**: 『가상 면접 사례로 배우는 대규모 시스템 설계 기초 2』 1장 Proximity Service

## 1. 테스트 환경

- **인프라**: 로컬 Docker Compose (단일 머신)
- **서버**: Spring Boot 3.4.1 (Java 21) 단일 인스턴스
- **DB**: MySQL 8.0 단일 인스턴스 + Redis 7 단일 인스턴스
- **모니터링**: Prometheus v2.54.1 + Grafana 11.4.0
- **부하 도구**: k6 0.55.0

## 2. 책의 요구사항 vs 실제 결과

### 책에서 제시한 규모

| 항목 | 수치 |
|------|------|
| 사업장 수 | 2억 건 |
| DAU | 1억 명 |
| 평균 QPS (읽기) | 5,800 |
| 응답 시간 목표 | 100ms 이내 |

### 소규모 테스트 (통과)

| 테스트 | 데이터 | VU | p95 | RPS | 에러율 | 판정 |
|--------|--------|-----|-----|-----|--------|------|
| nearby-search | 1,000건 | 50 | 11.21ms | 325.9 | 0% | PASS |
| crud-mixed | 500건 | 20 | 12.71ms | 160.8 | 0.05% | PASS |

### 대규모 테스트 (실패)

| 테스트 | 데이터 | VU | p95 | RPS | 에러율 | 판정 |
|--------|--------|-----|-----|-----|--------|------|
| nearby-search | 100,000건 | 500 | **41.3초** | 10 | 0% | **FAIL** |
| crud-mixed | 100,000건 | 200 | **60초** (타임아웃) | 4.3 | 28.96% | **FAIL** |

## 3. 병목 분석

### 3-1. 검색 응답 크기 폭발 (가장 심각)

```
소규모: 1,000건 중 반경 5km 내 → 수십 건 반환 → 수 KB 응답
대규모: 100,000건 중 반경 5km 내 → 수만 건 반환 → 약 2MB 응답
```

- 총 수신 데이터: 3.3 GB (1,721 요청)
- 요청당 평균: ~2 MB
- 서버가 응답을 직렬화하는 시간 + 네트워크 전송 시간이 대부분

**근본 원인**: 검색 결과 수 제한(페이지네이션)이 없음. Redis GEOSEARCH가 반경 내 모든 결과를 반환하고, 그 결과를 전부 MySQL에서 조회하여 응답에 포함.

### 3-2. MySQL 커넥션 고갈

- HikariCP 기본 풀 사이즈: 10
- 500 VU가 동시에 요청하면 490개가 커넥션 대기
- 검색 결과가 수만 건이면 각 커넥션 점유 시간도 증가
- 대기 큐가 쌓이면서 전체 latency 폭발

### 3-3. 단일 서버 한계

- Spring Boot 기본 톰캣 스레드: 200
- 500 VU 동시 요청 시 300개가 스레드 큐에 대기
- 각 요청이 수만 건을 처리하느라 스레드 반환이 느림
- 결과적으로 스레드 풀 포화 → 요청 타임아웃

### 3-4. Redis GEOSEARCH 부하

- 100,000건 중 반경 5km 검색 시 수만 건의 member를 반환
- Redis는 빠르지만, 수만 건의 ID를 한 번에 전송하는 것 자체가 부하
- 이후 MySQL에서 수만 건을 IN 쿼리로 조회하는 것이 추가 병목

## 4. CRUD API별 성공률 (대규모 테스트)

| API | 성공률 | 분석 |
|-----|--------|------|
| GET /v1/search/nearby | 52% | 검색 응답 크기로 인한 타임아웃 |
| GET /v1/businesses/:id | 93% | PK 단건 조회라 상대적으로 빠름 |
| POST /v1/businesses | 70% | DB 쓰기 + Redis 동기화에 커넥션 대기 |
| PUT /v1/businesses/:id | 90% | 단건 쓰기라 상대적으로 빠름 |
| DELETE /v1/businesses/:id | 50% | 샘플 수 적음 (2건 중 1건 실패) |

## 5. 책의 해결책 vs 개선 방향

| 병목 | 책의 해결책 | 다음 Phase 구현 방향 |
|------|------------|---------------------|
| 검색 결과 폭발 | 페이지네이션 + 결과 수 제한 | GEOSEARCH COUNT 옵션으로 최대 결과 수 제한 (20건) |
| 단일 서버 한계 | 수평 확장 (로드밸런서 + N대) | Docker Compose로 앱 인스턴스 2~3대 + Nginx 로드밸런서 |
| DB 커넥션 고갈 | 읽기 복제본 분리 + 풀 튜닝 | HikariCP 풀 사이즈 조정 + 읽기 전용 커넥션 분리 |
| 2억 건 메모리 | 데이터 샤딩 (지역별 분산) | 로컬 환경 한계로 Skip (설계만 문서화) |
| Redis 대량 반환 | Geohash 격자 기반 효율 조회 | 이미 Redis GEO 사용 중, COUNT 제한으로 해결 가능 |

## 6. 결론

소규모(1,000건, 50 VU)에서는 모든 성능 기준을 여유 있게 통과했지만, 책의 규모(100,000건, 500 VU)에서는 시스템이 완전히 무너졌다.

가장 큰 병목은 **검색 결과 수 제한이 없는 것**이다. 이 한 가지만 해결해도 응답 크기가 2MB → 수 KB로 줄어들어 대부분의 성능 문제가 완화될 것으로 예상된다.

다음 Phase에서는:
1. 검색 결과 페이지네이션 (최대 20건)
2. 앱 수평 확장 (Nginx + 멀티 인스턴스)
3. DB 커넥션 풀 튜닝

순서로 개선하고 동일 조건에서 재테스트하여 개선 효과를 측정한다.
