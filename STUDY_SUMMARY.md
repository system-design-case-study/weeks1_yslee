# Proximity Service 스터디 정리

> 『가상 면접 사례로 배우는 대규모 시스템 설계 기초 2』 1장을 직접 구현하며 배운 것들.
> 소규모에서 잘 동작하는 시스템이 대규모에서 어떻게 무너지는지 체험하고, 책의 설계 원칙이 왜 필요한지 검증한 과정.

---

## 1. 출발점: 책의 요구사항 정리

책에서 제시하는 Proximity Service의 규모:

| 항목 | 수치 |
|------|------|
| 사업장 수 | 2억 건 |
| DAU | 1억 명 |
| 평균 QPS | 5,800 |
| 응답 시간 목표 | 100ms 이내 |

이 규모를 처리하려면 단순히 "MySQL에 좌표 넣고 쿼리"로는 불가능하다. 책에서는 여러 설계 원칙을 제시하는데, 이것들이 정말 필요한지 직접 만들어보며 검증하고 싶었다.

**핵심 질문: "책에서 말하는 설계 원칙이 없으면 실제로 어떤 일이 벌어지는가?"**

---

## 2. Phase 1 — 주변 검색 API: 저장소를 어떻게 나눌 것인가

### 고민한 것

"위치 기반 검색"을 어떻게 구현할지가 첫 번째 결정이었다.

**선택지 3가지를 비교했다:**

| 방식 | 장점 | 단점 |
|------|------|------|
| MySQL ST_Distance_Sphere | 구현 단순 | 풀스캔 or 느린 공간 인덱스. 10만 건 이상에서 수십~수백 ms |
| Redis GEO만 | 검색 < 1ms | 좌표+ID만 저장 가능. 상세 정보 저장 불가. 영속성 약함 |
| **Redis GEO + MySQL** | 검색은 빠르고, 데이터는 안전 | 두 저장소 동기화 필요 |

**결론: Redis GEO를 검색 인덱스로, MySQL을 원본 데이터로 분리하자.**

### 설계한 것

**2단계 조회 패턴:**

```
1. Client → API: "내 위치 반경 5km 검색해줘"
2. API → Redis: GEOSEARCH → ID + 거리 목록 (< 1ms)
3. API → MySQL: findAllByIdIn(ids) → 상세 정보 (수 ms)
4. API → Client: 병합 + 거리순 정렬 → 응답
```

왜 Redis에 상세 정보까지 안 넣었는가?
- 2억 건 × (ID+좌표+이름+주소+전화번호...) = **수백 GB 메모리** → 비현실적
- 2억 건 × (ID+좌표만) = **~20 GB** → 현실적
- MySQL PK 조회 20건 추가 비용은 수 ms에 불과

### 구현한 것

```
controller/NearbySearchController.java  → GET /v1/search/nearby
service/NearbySearchService.java        → 2단계 조회 로직
repository/BusinessGeoRepository.java   → Redis GEOSEARCH 래핑
repository/BusinessRepository.java      → MySQL JPA
```

### 이때 알게 된 것

- Redis GEO는 내부적으로 Sorted Set + Geohash 인코딩을 사용한다
- **같은 좌표를 넣어도 GEODIST가 정확히 0.0m을 반환하지 않는다** (~0.x meters). 52비트 geohash 인코딩의 정밀도 한계 때문
- 테스트에서 `distance == 0.0` 대신 `distance < 1.0`으로 검증해야 한다

---

## 3. Phase 2 — CRUD API: 두 저장소를 어떻게 동기화할 것인가

### 고민한 것

Redis와 MySQL 두 군데에 데이터를 쓰는데, 이 둘의 정합성을 어떻게 보장할 것인가?

**선택지 3가지를 비교했다:**

| 방식 | 정합성 | 복잡도 | 비고 |
|------|--------|--------|------|
| 분산 트랜잭션 (2PC) | 강한 일관성 | 매우 높음 | Redis는 2PC를 지원하지 않음 |
| CDC (Change Data Capture) | 최종 일관성 | 높음 | Debezium, Kafka 등 인프라 추가 필요 |
| **앱 레벨 동기화** | 최종 일관성 | 낮음 | 단순하고 디버깅 쉬움 |

**결론: 앱 레벨 동기화로 충분하다.**

이유:
1. 검색 인덱스는 1~2초 늦어도 서비스에 영향 없다 (최종 일관성 OK)
2. 실패 시 복구 경로가 명확하다 (`@Retryable` → 배치)
3. Kafka나 Debezium 없이 Spring Boot만으로 완결된다

### 설계한 것

```
CREATE: MySQL INSERT → Redis GEOADD
UPDATE: MySQL UPDATE → 좌표 변경 시에만 Redis GEOADD (메타데이터만 변경 시 Redis 호출 안 함)
DELETE: MySQL DELETE → Redis ZREM

실패 시: @Retryable(3회, 1s → 2s → 4s 지수 백오프) → 실패 로깅 → 배치로 복구
```

### 이때 알게 된 것

- `@Retryable`은 `spring-retry` + `spring-boot-starter-aop` 의존성이 모두 필요하다
- UPDATE 시 좌표 변경 여부를 체크해서 불필요한 Redis 호출을 방지하는 최적화가 중요하다
- MySQL 트랜잭션이 커밋된 후 Redis 동기화가 실패해도 데이터는 안전하다 (MySQL이 진실의 원천)

---

## 4. Phase 3 — 배치 복구: 동기화가 깨지면 어떻게 복구하는가

### 고민한 것

앱 레벨 동기화는 "최선의 노력"이다. Redis가 다운되거나 네트워크가 끊기면 MySQL에는 있지만 Redis에는 없는 데이터가 생긴다. 이걸 어떻게 복구할 것인가?

### 설계한 것

**두 종류의 배치를 만들었다:**

| 배치 | 용도 | 동작 |
|------|------|------|
| **Full Sync** | Redis 완전 재구축 | Redis 전부 삭제 → MySQL 전체 데이터를 500건씩 Redis에 재적재 |
| **Consistency Check** | 차이점 탐지 + 자동 복구 | MySQL ID 집합과 Redis ID 집합을 비교 → 누락 추가, 고아 제거 |

**동시 실행 방지:**

```java
private final AtomicBoolean running = new AtomicBoolean(false);

if (!running.compareAndSet(false, true)) {
    throw new IllegalStateException("A batch job is already running");
}
```

### 이때 알게 된 것

- 전체 데이터를 한 번에 로딩하면 메모리가 터진다 → **500건씩 페이지네이션** 필수
- Full Sync는 Redis를 완전히 지우고 다시 쓰기 때문에 실행 중 검색이 안 된다 → 운영에서는 새 키로 구축 후 교체하는 전략이 필요
- `AtomicBoolean`으로 동시 실행 방지가 간단하고 효과적

---

## 5. Phase 4 — 테스트: 설계 원칙이 정말 지켜지고 있는가

### 고민한 것

Phase 1~3에서 구현은 했는데, 책의 설계 원칙이 실제로 지켜지는지 어떻게 검증할 것인가?

### 설계한 것

**5가지 관점의 테스트를 만들었다:**

| 검증 관점 | 테스트 | 핵심 검증 |
|-----------|--------|-----------|
| Geohash 정밀도 | GeohashAccuracyTest (8개) | 반경 내 결과만 나오는가, 경계값은 정확한가 |
| 읽기/쓰기 분리 | ReadWriteSeparationTest (6개) | Redis 삭제하면 검색 결과 0건인가 (읽기 경로 검증) |
| 이중 저장소 정합성 | DualStorageConsistencyTest (6개) | CRUD 후 MySQL과 Redis가 일치하는가 |
| 캐싱 전략 | CachingStrategyTest (5개) | Redis에 ID+좌표만 저장하는가, 상세 정보는 MySQL에서 오는가 |
| 동기화 복구 | SyncRecoveryVerificationTest (5개) | Full Sync와 Consistency Check가 정합성을 복구하는가 |

**성능 테스트 (별도 실행):**

| 테스트 | 내용 |
|--------|------|
| SearchLatencyTest | p50/p95/p99 지연시간 측정 |
| ConcurrentSearchTest | 10스레드 × 50 동시 검색 |
| LargeDatasetTest | 10,000~100,000건에서의 검색 성능 |
| BatchProcessingPerformanceTest | 1,000건 배치 처리 시간 |

**E2E 시나리오 테스트:**

| 시나리오 | 검증 |
|----------|------|
| 사업장 라이프사이클 | 생성 → 검색 → 수정(이동) → 삭제 전체 흐름 |
| Redis 장애 복구 | Redis 삭제 → Full Sync → 검색 결과 복구 확인 |
| 정합성 복구 | 의도적 불일치 발생 → Consistency Check → 자동 복구 확인 |
| 다중 위치 검색 | 서울 5개 랜드마크에서 동시 검색 |

### 이때 알게 된 것

**Testcontainers 싱글턴 패턴 문제:**

처음에 `@Container` + `@Testcontainers`를 추상 부모 클래스에 썼더니, 첫 번째 자식 테스트 클래스가 끝나면 컨테이너가 멈췄다. 이후 테스트 클래스들이 전부 연결 실패.

**해결:** static initializer + `@DynamicPropertySource` 패턴으로 변경하여 싱글턴 컨테이너를 전체 테스트 스위트에서 공유.

**Gradle 테스트 태그 문제:**

`tasks.withType<Test>`로 `excludeTags`를 설정하면 커스텀 `performanceTest` 태스크에도 적용된다. `tasks.named<Test>("test")`로 스코프를 한정해야 한다.

---

## 6. Phase 5 — 부하 테스트: 소규모 vs 대규모, 무엇이 다른가

### 고민한 것

JUnit 테스트는 프로세스 내부에서 실행되므로 네트워크, 직렬화, 동시성 이슈를 잡지 못한다. 실제 HTTP 요청으로 대규모 부하를 줘보면 어떻게 될까?

### 설계한 것

**k6 + Prometheus + Grafana 모니터링 스택:**

```
k6 (부하 생성) → HTTP → Spring Boot API → Redis + MySQL
                                  ↓
                          /actuator/prometheus
                                  ↓
                            Prometheus (수집)
                                  ↓
                            Grafana (시각화)
```

**테스트 시나리오 2가지:**

1. **nearby-search.js**: 순수 검색 부하 (50 → 100 → 200 → 300 → 500 VU 점진 증가)
2. **crud-mixed.js**: 실제 트래픽 패턴 (검색 60% + 조회 20% + 생성 10% + 수정 5% + 삭제 5%)

**시드 데이터**: 서울 5개 랜드마크(강남/홍대/잠실/서울역/명동) 주변에 가우시안 분포로 10만 건 생성

### 테스트 결과

#### 소규모 (1,000건, 50 VU) — 통과

| 테스트 | p95 | RPS | 에러율 |
|--------|-----|-----|--------|
| nearby-search | 11ms | 326 | 0% |
| crud-mixed | 13ms | 161 | 0.05% |

**"아, 잘 되네. 문제없다."** — 이것이 함정이었다.

#### 대규모 (100,000건, 500 VU) — 완전 붕괴

| 테스트 | p95 | RPS | 에러율 |
|--------|-----|-----|--------|
| nearby-search | **41초** | 10 | 0% |
| crud-mixed | **60초 (타임아웃)** | 4 | **29%** |

**시스템이 완전히 무너졌다.**

### 원인을 분석한 것

Grafana 대시보드와 k6 메트릭을 분석해서 3가지 원인을 찾았다:

#### 원인 1: 검색 결과 수 제한 없음 (가장 치명적)

```
1,000건 → 반경 5km 내 ~50건 반환 → 응답 ~1 KB
100,000건 → 반경 5km 내 ~50,000건 반환 → 응답 ~2 MB
```

GEOSEARCH가 반경 내 **모든** 결과를 반환했다. 5만 건의 ID를 받아서, 5만 건을 MySQL에서 조회하고, 5만 건을 JSON으로 직렬화해서 응답으로 보냈다. **요청 하나당 2MB.** 500 VU가 동시에 보내면 초당 1GB의 응답 데이터를 만들어내야 했다.

**이 순간 깨달았다: 책에서 "검색 결과 제한"을 강조한 이유.**

#### 원인 2: DB 커넥션 풀 고갈

HikariCP 기본 풀은 10개. 각 요청이 5만 건을 처리하느라 커넥션을 수 초간 점유. 500 VU 중 490개가 커넥션 대기 큐에 쌓였다.

#### 원인 3: 톰캣 스레드 포화

기본 200개 스레드가 전부 느린 요청에 묶여서 새 요청을 받을 수 없었다. 요청 처리 시간이 길어지면서 연쇄적으로 전체가 밀렸다.

### 이때 알게 된 것

**"소규모에서 통과한 코드는 대규모를 보장하지 않는다."**

단위 테스트 98개가 전부 통과해도, 실제 부하 환경에서는 완전히 다른 문제가 발생한다. 응답 크기, 커넥션 풀, 스레드 풀 같은 자원 한계는 부하 테스트에서만 드러난다.

---

## 7. Phase 6 — 성능 개선: 무엇을 바꿨고, 얼마나 나아졌는가

### 적용한 개선

| 개선 | 변경 | 이유 |
|------|------|------|
| GEOSEARCH COUNT 20 | 결과 최대 20건으로 제한 | 응답 크기 2MB → 수 KB |
| HikariCP 풀 확대 | 10 → 50 | 500 VU 동시 처리를 위한 커넥션 확보 |

### 개선 결과

| 테스트 | 개선 전 p95 | 개선 후 p95 | 변화 |
|--------|------------|------------|------|
| nearby-search | 41초 | **2.1초** | **20배 개선** |
| crud-mixed | 60초 (타임아웃) | **2.08초** | **에러율 29% → 0.1%** |

**검색 결과 제한 하나가 가장 큰 차이를 만들었다.**

응답 크기가 2MB → 수 KB로 줄자:
- 직렬화 시간 감소
- 네트워크 전송 시간 감소
- MySQL 조회량 감소 (5만 건 → 20건)
- 커넥션 점유 시간 감소
- 전체 시스템에 연쇄적으로 긍정적 효과

### 그래도 남은 것

p95 2.1초는 여전히 책의 목표(100ms)에 한참 미달이다. 하지만 이건 아키텍처의 문제가 아니다.

**로컬 Docker 단일 인스턴스의 물리적 한계:**
- App, MySQL, Redis가 같은 CPU/RAM/디스크를 공유
- Docker 브리지 네트워크 오버헤드
- 같은 PC에서 MySQL 읽기 복제본을 추가해도 하드웨어를 나눠 쓰는 것이므로 효과 없음

100ms 달성을 위해서는 별도 하드웨어에 분산하는 수밖에 없다:

| 단계 | 전략 | 기대 효과 |
|------|------|----------|
| 1 | 수평 확장 (Nginx + 멀티 인스턴스) | 동시 처리 N배 (코드 변경 없음) |
| 2 | MySQL 읽기 복제본 | DB 읽기 병목 해소 |
| 3 | Redis Cluster 샤딩 | 2억 건 분산 |
| 4 | 응답 캐싱 | 동일 지역 반복 검색 즉시 응답 |

---

## 8. 전체를 돌아보며

### 각 Phase에서 얻은 핵심 교훈

| Phase | 핵심 교훈 |
|-------|-----------|
| 1 | 저장소는 역할에 따라 나눠야 한다. Redis는 검색, MySQL은 데이터 |
| 2 | 동기화는 단순할수록 좋다. 분산 트랜잭션보다 앱 레벨 + 배치 복구 |
| 3 | 실패는 반드시 발생한다. 복구 경로를 미리 설계해야 한다 |
| 4 | 테스트는 "동작 확인"이 아니라 "설계 원칙 검증"이어야 한다 |
| 5 | **소규모 성공은 대규모를 보장하지 않는다. 부하 테스트는 필수** |
| 6 | 가장 큰 병목은 의외로 단순하다 (응답 크기 제한 하나로 20배 개선) |

### 책의 설계 원칙이 정말 필요한가?

**직접 실패해보니 전부 필요했다.**

| 원칙 | 없으면 어떻게 되는지 (직접 경험) |
|------|-------------------------------|
| 읽기/쓰기 분리 | MySQL만으로 검색하면 10만 건에서 수백 ms |
| 데이터 지역성 | Redis에 다 넣으면 메모리 수백 GB |
| 검색 결과 제한 | 제한 없으면 응답 2MB → p95 41초 → 서비스 불가 |
| 앱 레벨 동기화 | 분산 트랜잭션은 Redis가 지원 안 하고, CDC는 인프라 과잉 |
| 배치 복구 | 동기화 실패 시 복구 수단이 없으면 데이터 불일치 누적 |

### 프로젝트 타임라인

```
Day 1-2  │ Phase 1: 주변 검색 API (Redis GEO + MySQL 2단계 조회)
Day 3    │ Phase 2: CRUD API (앱 레벨 동기화 + @Retryable)
Day 4    │ Phase 3: 배치 복구 (Full Sync + Consistency Check)
Day 5    │ Phase 4: 테스트 98개 (설계 원칙 검증 + 성능 + E2E)
Day 6    │ Phase 5: k6 부하 테스트 + Prometheus/Grafana → 대규모 실패 경험
Day 7    │ Phase 6: 성능 개선 (COUNT 20 + HikariCP 튜닝) → 20배 개선
```

### 한 문장 요약

> **"작은 규모에서 동작하는 코드와 큰 규모에서 동작하는 시스템은 완전히 다른 문제이며, 그 차이를 메우는 것이 시스템 설계 원칙이다."**
